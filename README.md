# ä»€éº¼æ˜¯ Blender-Docs-RAG-Assistantï¼Ÿ

Blender å®˜æ–¹çš„ç¹é«”ä¸­æ–‡æ‰‹å†Šï¼Œå¤§éƒ¨åˆ†ä»éƒ½æ˜¯è‹±æ–‡ï¼Œå°±ç®—æœƒè‹±æ–‡ï¼Œæƒ³å‡ºè‹±æ–‡é—œéµå­—æŸ¥è©¢æ–‡ä»¶å›°é›£åˆè€—æ™‚ã€‚
Blender-Docs-RAG-Assistant è®“ä½ å¯ä»¥ç›´æ¥ç”¨ç¹é«”ä¸­æ–‡æå•ï¼Œ
å¿«é€Ÿå¾å®Œæ•´å®˜æ–¹æ–‡ä»¶ä¸­æ‰¾åˆ°ç­”æ¡ˆï¼Œä¸¦ä»¥ä¸­æ–‡æ¸…æ¥šå›è¦†ã€‚

---

# æœ¬åœ°ä¾è³´éœ€æ±‚ï¼ˆWindowsï¼‰

- å®‰è£ [Docker Desktop for Windows](https://www.docker.com/products/docker-desktop/)ï¼ˆå»ºè­°å®‰è£æœ€æ–°ç‰ˆï¼‰
- ç¢ºèª Docker Desktop è¨­å®šå•Ÿç”¨ WSL2
ï¼ˆSettings â†’ Resources â†’ WSL integration â†’ å‹¾é¸ã€ŒEnable integration with my default WSL distroã€ï¼‰

## ç¢ºèªç’°å¢ƒæˆåŠŸ

è«‹åˆ†åˆ¥åŸ·è¡Œä»¥ä¸‹æŒ‡ä»¤ï¼Œä¸¦æ¯”å°è¼¸å‡ºçµæœï¼š

```bash
docker --version
docker compose version
```
âœ… æ­£å¸¸æ‡‰é¡¯ç¤º Docker ç‰ˆæœ¬èˆ‡ Docker Compose ç‰ˆæœ¬

```bash
docker info | findstr /i nvidia
```
âœ… æ­£å¸¸æ‡‰è©²èƒ½çœ‹åˆ°åŒ…å« `nvidia` çš„å­—æ¨£ï¼Œä¾‹å¦‚ï¼š
`Runtimes: io.containerd.runc.v2 nvidia runc`
å¦‚æœæœ‰çœ‹åˆ° `nvidia` å‡ºç¾ï¼Œä»£è¡¨ GPU æ”¯æ´è¨­å®šæˆåŠŸã€‚

---

# ä½¿ç”¨æµç¨‹

## 1. Buildï¼šå»ºç«‹è³‡æ–™

```bash
docker compose --profile build up blender-rag-build
```

è™•ç†å…§å®¹ï¼š
- ä¸‹è¼‰ Blender å®˜æ–¹æ‰‹å†Š
- æ¸…ç† HTML æˆç´”æ–‡å­—
- åˆ†æ®µ (chunk)
- å»ºç«‹ FAISS å‘é‡è³‡æ–™åº«

## 2. Deployï¼šå•Ÿå‹•æœå‹™

```bash
docker compose up
```

å•Ÿå‹•å…§å®¹ï¼š
- å•Ÿå‹• Ollama æœå‹™ (http://localhost:11434)
- å•Ÿå‹• Blender-RAG æŸ¥è©¢ API server (http://localhost:7860)

Blender-RAG æŸ¥è©¢ API server å·¥ä½œæµç¨‹ï¼š
1. æ¥æ”¶ä½¿ç”¨è€…çš„ä¸­æ–‡å•é¡Œ
2. é€²è¡Œå‘é‡åŒ–ï¼ˆEmbeddingï¼‰
3. å¾ Blender æ‰‹å†Šä¸­æª¢ç´¢æœ€ç›¸é—œæ®µè½
4. çµ„åˆæˆ Promptï¼Œç™¼é€çµ¦æœ¬åœ°çš„ Ollama æ¨¡å‹
5. å–å¾—æ¨¡å‹å›è¦†å¾Œï¼Œå°‡ä¸­æ–‡å›ç­”å›å‚³çµ¦ä½¿ç”¨è€…

## 3. æ‹‰å–æ¨¡å‹

ç¬¬ä¸€æ¬¡å•Ÿå‹•æ™‚ï¼ŒOllama æœå‹™é è¨­æ²’æœ‰ä»»ä½•æ¨¡å‹ï¼Œéœ€è¦å…ˆæ‹‰å–ã€‚

ç¨‹å¼ç¢¼é è¨­ä½¿ç”¨çš„æ¨¡å‹æ˜¯ï¼š

```
gemma3:4b-it-q8_0
```

å¦‚æœä¸æ›´æ›æ¨¡å‹ï¼Œè«‹ç›´æ¥å‘ [Ollama çš„ API](https://github.com/ollama/ollama/blob/main/docs/api.md#pull-a-model) ç™¼é€ä»¥ä¸‹è«‹æ±‚ï¼š

```bash
curl -X POST http://localhost:11434/api/pull \
  -H "Content-Type: application/json" \
  -d '{"model": "gemma3:4b-it-q8_0"}'
```

å¦‚æœæƒ³æ›´æ›å…¶ä»–æ¨¡å‹ï¼š
- è«‹åƒè€ƒ Ollama å®˜æ–¹çš„[æ¨¡å‹åˆ—è¡¨](https://ollama.com/search)
- ä¸¦ä¿®æ”¹ `scripts/model_ollama.py` æª”æ¡ˆä¸­çš„ `OLLAMA_MODEL` è®Šæ•¸ã€‚

## æ³¨æ„äº‹é …

- é¦–æ¬¡ä½¿ç”¨å¿…é ˆå…ˆåŸ·è¡Œ `build`
- è‹¥ Blender æ‰‹å†Šæœ‰æ›´æ–°ï¼Œé‡æ–° `build`å³å¯

---

# ä½¿ç”¨æ–¹å¼

## 1. æ­é… Web UI ä½¿ç”¨

Blender-Docs-RAG-Assistant é è¨­æä¾› API ä»‹é¢ï¼Œè‹¥å¸Œæœ›é€éç¶²é ä»‹é¢æŸ¥è©¢ï¼ˆç„¡éœ€æ’°å¯«ç¨‹å¼æˆ–ä½¿ç”¨ curlï¼‰ï¼Œ
å¯æ­é…å…¬é–‹éƒ¨ç½²çš„å‰ç«¯ç¶²ç«™ä½¿ç”¨ï¼š

ğŸ‘‰ [Blender-RAG-Assistant Web UI](https://1ureka.github.io/assistant)

é–‹å•Ÿå¾Œï¼Œè‹¥æœ‰æ›´æ›ééƒ¨å±¬ä½å€ï¼Œè«‹é»é¸å·¦ä¸‹è§’çš„ã€Œè¨­å®šã€æŒ‰éˆ•ï¼Œè¼¸å…¥æœ¬æ©Ÿ API çš„ä½å€ï¼ˆä¾‹å¦‚ `http://localhost:7860` æˆ–å€ç¶² IP ä½å€ï¼‰ï¼Œå³å¯é–‹å§‹æŸ¥è©¢ã€‚

æ­¤ UI è¨­è¨ˆç‚ºé–‹æ”¾å¼ç”¨æ³•ï¼Œé©åˆï¼š
- åœ¨å¤šå°è¨­å‚™ä¸Šå­˜å–è‡ªå·±éƒ¨å±¬çš„ APIï¼ˆä¾‹å¦‚é€é Hamachi æˆ–å€ç¶²åˆ†äº«ï¼‰
- å±•ç¤ºèˆ‡æ“ä½œ Blender æ–‡ä»¶çš„ä¸­æ–‡æŸ¥è©¢ä»‹é¢
- ä¸æƒ³æ’°å¯«é¡å¤–å‰ç«¯çš„äººå¿«é€Ÿé«”é©—æŸ¥è©¢æ•ˆæœ

## 2. ä½¿ç”¨ API ç«¯é»

API ä¼ºæœå™¨é‹è¡Œæ–¼ `http://localhost:7860`ï¼Œæä¾›ä»¥ä¸‹ç«¯é»ï¼š

| ç«¯é»      | æ–¹æ³•   | èªªæ˜                      |
|----------|-------|--------------------------|
| `/`      | GET   | ç²å– API åŸºæœ¬è³‡è¨Šèˆ‡ç‹€æ…‹      |
| `/status`| GET   | æª¢æŸ¥æœå‹™æ˜¯å¦å·²æº–å‚™å°±ç·’        |
| `/query` | GET   | å‘ Blender æ‰‹å†Šæå‡ºæŸ¥è©¢å•é¡Œ  |

## `/`

ä»¥ä¸‹æ˜¯ä½¿ç”¨ TypeScript è¨ªå•æ ¹ç«¯é»çš„ç¤ºä¾‹ä»£ç¢¼ï¼Œè¿”å› API çš„åŸºæœ¬ä¿¡æ¯ï¼š

```typescript
interface ApiEndpoint {
  path: string;
  method: string;
  description: string;
}

interface ApiInfo {
  service: string;
  version: string;
  status: string;
  endpoints: ApiEndpoint[];
}

/**
 * ç²å– Blender-RAG API çš„åŸºæœ¬ä¿¡æ¯
 * @returns API åŸºæœ¬ä¿¡æ¯
 */
async function getApiInfo(): Promise<ApiInfo> {
  const response = await fetch('http://localhost:7860/');
  if (!response.ok) {
    throw new Error(`HTTP error! Status: ${response.status}`);
  }
  return await response.json() as ApiInfo;
}

// ä½¿ç”¨ç¤ºä¾‹
getApiInfo()
  .then(info => {
    console.log(`æœå‹™åç¨±: ${info.service}`);
    console.log(`ç‰ˆæœ¬: ${info.version}`);
    console.log(`ç‹€æ…‹: ${info.status}`);
    console.log('å¯ç”¨ç«¯é»:');
    info.endpoints.forEach(endpoint => {
      console.log(`- ${endpoint.path} (${endpoint.method}): ${endpoint.description}`);
    });
  })
  .catch(error => console.error('ç²å– API ä¿¡æ¯æ™‚å‡ºéŒ¯:', error));
```

## `/status`

åœ¨é€²è¡ŒæŸ¥è©¢å‰ï¼Œå»ºè­°å…ˆæª¢æŸ¥æœå‹™æ˜¯å¦å·²æº–å‚™å°±ç·’ï¼š

```typescript
interface StatusResponse {
  ready: boolean;
  timestamp: number;
  message: string;
}

/**
 * æª¢æŸ¥ Blender-RAG API æœå‹™ç‹€æ…‹
 * @returns æœå‹™ç‹€æ…‹ä¿¡æ¯
 */
async function checkApiStatus(): Promise<StatusResponse> {
  const response = await fetch('http://localhost:7860/status');
  if (!response.ok) {
    throw new Error(`HTTP error! Status: ${response.status}`);
  }
  return await response.json() as StatusResponse;
}

// ä½¿ç”¨ç¤ºä¾‹
checkApiStatus()
  .then(status => {
    if (status.ready) {
      console.log(`æœå‹™å·²å°±ç·’: ${status.message}`);
      console.log(`æ™‚é–“æˆ³: ${new Date(status.timestamp * 1000).toLocaleString()}`);
      // æœå‹™å°±ç·’ï¼Œå¯ä»¥é–‹å§‹æŸ¥è©¢
      startQuerying();
    } else {
      console.log(`æœå‹™å°šæœªå°±ç·’: ${status.message}`);
      console.log('è«‹ç¨å¾Œå†è©¦...');
      // å¯ä»¥è¨­ç½®å®šæ™‚å™¨ç¨å¾Œå†æ¬¡æª¢æŸ¥
      setTimeout(checkApiStatus, 5000);
    }
  })
  .catch(error => console.error('æª¢æŸ¥ API ç‹€æ…‹æ™‚å‡ºéŒ¯:', error));
```

## `/query`

API æä¾›çš„æ˜¯ Server-Sent Events (SSE) æ ¼å¼çš„æµå¼å›æ‡‰ï¼Œä»¥ä¸‹æ˜¯ä½¿ç”¨ TypeScript å¯¦ç¾çš„æŸ¥è©¢åŠŸèƒ½ï¼š

```typescript
interface QueryOptions {
  onData?: (text: string) => void; // æ¥æ”¶æµå¼æ•¸æ“šçš„å›èª¿
  onComplete?: () => void; // æ•¸æ“šæµçµæŸæ™‚çš„å›èª¿
  onError?: (error: Error) => void; // ç™¼ç”ŸéŒ¯èª¤æ™‚çš„å›èª¿
}

/**
 * å‘ Blender RAG API ç™¼é€æŸ¥è©¢ä¸¦è™•ç†æµå¼éŸ¿æ‡‰
 * @param question è¦æŸ¥è©¢çš„å•é¡Œ
 * @param options æŸ¥è©¢é¸é …
 * @returns åŒ…å«é—œé–‰é€£æ¥æ–¹æ³•çš„å°è±¡
 */
function queryBlenderRAG(question: string, options: QueryOptions = {}) {
  // é è¨­é¸é …
  const {
    onData = (text: string) => console.log(text),
    onError = (error: Error) => console.error('æŸ¥è©¢éŒ¯èª¤:', error),
    onComplete = () => console.log('æŸ¥è©¢å®Œæˆ'),
  } = options;

  // ç·¨ç¢¼æŸ¥è©¢åƒæ•¸
  const encodedQuestion = encodeURIComponent(question);
  const url = `http://localhost:7860/query?question=${encodedQuestion}`;

  // ç´¯ç©çš„å›æ‡‰æ–‡æœ¬
  let fullResponse = '';

  // å‰µå»º EventSource é€£æ¥
  const eventSource = new EventSource(url);

  // è™•ç†æ”¶åˆ°çš„æ•¸æ“š
  eventSource.onmessage = (event) => {
    const text = event.data;
    fullResponse += text;
    onData(text);
  };

  // è™•ç†é€£æ¥å®Œæˆ
  eventSource.onopen = () => {
    console.log('SSE é€£æ¥å·²å»ºç«‹');
  };

  // è™•ç†éŒ¯èª¤
  eventSource.onerror = (error) => {
    eventSource.close();
    if (fullResponse) {
      // å¦‚æœå·²æ”¶åˆ°éƒ¨åˆ†å›æ‡‰ï¼Œè¦–ç‚ºå®Œæˆ
      onComplete();
    } else {
      // å¦å‰‡è¦–ç‚ºéŒ¯èª¤
      onError(new Error('SSE é€£æ¥éŒ¯èª¤'));
    }
  };

  // è¿”å›æ§åˆ¶å°è±¡
  return {
    close: () => {
      eventSource.close();
      onComplete();
    },
    getFullResponse: () => fullResponse
  };
}
```

---

# docker-compose.yml æ¦‚è¦

```yaml
services:
  ollama:
    image: ollama/ollama
    ports:
      - "11434:11434"
    volumes:
      - ./data/ollama:/root/.ollama
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [gpu]

  blender-rag-build:
    build: .
    profiles: ["build"]
    volumes:
      - .:/app
    command: python scripts/build.py
    environment:
      - PYTHONPATH=/app
    tty: true
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [gpu]

  blender-rag-deploy:
    build: .
    ports:
      - "7860:7860"
    volumes:
      - .:/app
    command: uvicorn app.api:app --host 0.0.0.0 --port 7860
    depends_on:
      - ollama
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [gpu]
```

- å•Ÿå‹• **ollama** ä½œç‚ºæœ¬åœ° LLM API æœå‹™ (11434 ç«¯å£)
- ä½¿ç”¨ **blender-rag-build** é€²è¡Œè³‡æ–™è™•ç†ï¼ˆå¿…é ˆæŒ‡å®š profileï¼‰
- ä½¿ç”¨ **blender-rag-deploy** å•Ÿå‹•æŸ¥è©¢æœå‹™

---

# Dockerfile æ¦‚è¦

```Dockerfile
FROM pytorch/pytorch:2.5.1-cuda12.1-cudnn9-runtime

WORKDIR /app

COPY requirements.txt .

RUN pip install --no-cache-dir --upgrade pip \
 && pip install --no-cache-dir --requirement requirements.txt

RUN python -c "from sentence_transformers import SentenceTransformer; SentenceTransformer('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')"
```

---

# requirements.txt æ¦‚è¦

```text
markdownify              # å°‡ HTML è½‰æ›æˆç´”æ–‡å­—æ ¼å¼ï¼ˆMarkdownï¼‰
lxml                     # è§£æèˆ‡è™•ç† HTML/XML
requests                 # ä¸‹è¼‰ Blender å®˜æ–¹æ‰‹å†Š ZIP æª”æ¡ˆ
hf_xet                   # åŠ é€Ÿ Hugging Face æ¨¡å‹ä¸‹è¼‰ï¼ˆå¯é¸ï¼‰
sentence-transformers    # ä¸­æ–‡/å¤šèªè¨€å‘é‡åŒ–ï¼ˆEmbeddingï¼‰
faiss-gpu-cu12           # GPU åŠ é€Ÿçš„å‘é‡æœå°‹è³‡æ–™åº« FAISS
torch
transformers
uvicorn                  # è¼•é‡ç´š ASGI ä¼ºæœå™¨
fastapi                  # é«˜æ•ˆèƒ½ API æ¡†æ¶
opencc                   # è¬ä¸€AIä»ä¸å°å¿ƒè¿”å›ç°¡é«”ï¼Œè½‰æ›æˆç¹é«”ä¸­æ–‡
```

---

# å®Œæ•´æ¨¹ç‹€åœ–

```bash
blender.docs.rag/
â”œâ”€â”€ app/
â”‚   â””â”€â”€ api.py       # æä¾›æŸ¥è©¢ API
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ html/        # åŸå§‹ HTML è³‡æ–™
â”‚   â”œâ”€â”€ texts/       # æ¸…ç†å¾Œçš„ç´”æ–‡å­—
â”‚   â”œâ”€â”€ index/       # FAISS å‘é‡è³‡æ–™åº«
â”‚   â””â”€â”€ ollama/      # Ollama æ¨¡å‹è³‡æ–™
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ build.py             # ä¸»è¦æ•´åˆè…³æœ¬ï¼Œçµ±ä¸€å”èª¿è™•ç†æµç¨‹
â”‚   â”œâ”€â”€ build_download.py    # ä¸‹è¼‰ Blender å®˜æ–¹æ‰‹å†Š ZIP æª”æ¡ˆ
â”‚   â”œâ”€â”€ build_clean.py       # å°‡ HTML è½‰æ›æˆç´”æ–‡å­—æ ¼å¼
â”‚   â”œâ”€â”€ build_vectorize.py   # æ–‡æœ¬åˆ†æ®µä¸¦å»ºç«‹å‘é‡ç´¢å¼•
â”‚   â”œâ”€â”€ build_validate.py    # é©—è­‰å‘é‡ç´¢å¼•åŠŸèƒ½æ­£ç¢ºæ€§
â”‚   â”œâ”€â”€ model_embedding.py   # å¤šèªè¨€å‘é‡åµŒå…¥æ¨¡å‹ç®¡ç†
â”‚   â”œâ”€â”€ model_faiss.py       # FAISS å‘é‡ç´¢å¼•ç®¡ç†èˆ‡æŸ¥è©¢
â”‚   â”œâ”€â”€ model_ollama.py      # Ollama API ä¸²æ¥èˆ‡è™•ç†
â”‚   â””â”€â”€ query.py             # æŸ¥è©¢è™•ç†èˆ‡ Prompt çµ„åˆ
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

è¨»ï¼š
- [Blender å®˜æ–¹æ‰‹å†Š](https://docs.blender.org/manual/en/latest/blender_manual_html.zip)
