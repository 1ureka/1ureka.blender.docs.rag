# Blender-Manual-RAG-Assistant - ä½¿ç”¨æŒ‡å—

---

## ğŸ–¥ï¸ æœ¬åœ°ä¾è³´éœ€æ±‚ï¼ˆWindowsï¼‰

- å®‰è£ [Docker Desktop for Windows](https://www.docker.com/products/docker-desktop/)ï¼ˆå»ºè­°å®‰è£æœ€æ–°ç‰ˆï¼‰
- ç¢ºèª Docker Desktop è¨­å®šå•Ÿç”¨ WSL2
ï¼ˆSettings â†’ Resources â†’ WSL integration â†’ å‹¾é¸ã€ŒEnable integration with my default WSL distroã€ï¼‰

### ç¢ºèªç’°å¢ƒæˆåŠŸ

è«‹åˆ†åˆ¥åŸ·è¡Œä»¥ä¸‹æŒ‡ä»¤ï¼Œä¸¦æ¯”å°è¼¸å‡ºçµæœï¼š

```bash
docker --version
docker compose version
```
âœ… æ­£å¸¸æ‡‰é¡¯ç¤º Docker ç‰ˆæœ¬èˆ‡ Docker Compose ç‰ˆæœ¬

```bash
docker info | findstr /i nvidia
```
âœ… æ­£å¸¸æ‡‰è©²èƒ½çœ‹åˆ°åŒ…å« `nvidia` çš„å­—æ¨£ï¼Œä¾‹å¦‚ï¼š
`Runtimes: io.containerd.runc.v2 nvidia runc`
å¦‚æœæœ‰çœ‹åˆ° `nvidia` å‡ºç¾ï¼Œä»£è¡¨ GPU æ”¯æ´è¨­å®šæˆåŠŸã€‚

---

## ğŸ› ï¸ docker-compose.yml æ¦‚è¦

```yaml
version: "3.8"

services:
  ollama:
    image: ollama/ollama
    ports:
      - "11434:11434"
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [gpu]

  blender-rag-build:
    build: .
    profiles: ["build"]
    volumes:
      - .:/app
    command: python scripts/build.py
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [gpu]

  blender-rag-deploy:
    build: .
    ports:
      - "7860:7860"
    volumes:
      - .:/app
    command: uvicorn app.api:app --host 0.0.0.0 --port 7860
    depends_on:
      - ollama
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [gpu]
```

- å•Ÿå‹• **ollama** ä½œç‚ºæœ¬åœ° LLM API æœå‹™ (11434 ç«¯å£)
- ä½¿ç”¨ **blender-rag-build** é€²è¡Œè³‡æ–™è™•ç†ï¼ˆå¿…é ˆæŒ‡å®š profileï¼‰
- ä½¿ç”¨ **blender-rag-deploy** å•Ÿå‹•æŸ¥è©¢æœå‹™

---

## ğŸ› ï¸ Dockerfile æ¦‚è¦

```Dockerfile
FROM pytorch/pytorch:2.5.1-cuda12.1-cudnn9-runtime

WORKDIR /app

COPY requirements.txt .

RUN pip install --no-cache-dir --upgrade pip \
 && pip install --no-cache-dir --requirement requirements.txt

COPY . .
```

---

## ğŸ› ï¸ requirements.txt æ¦‚è¦

```text
beautifulsoup4
lxml
requests
sentence-transformers
faiss-gpu-cu12
torch
transformers
uvicorn
fastapi
```

---

# ğŸš€ ä½¿ç”¨æµç¨‹

## 1. Buildï¼šå»ºç«‹è³‡æ–™

```bash
docker compose --profile build up blender-rag-build
```

è™•ç†å…§å®¹ï¼š
- ä¸‹è¼‰ Blender å®˜æ–¹æ‰‹å†Š
- æ¸…ç† HTML æˆç´”æ–‡å­—
- åˆ†æ®µ (chunk)
- å»ºç«‹ FAISS å‘é‡è³‡æ–™åº«

## 2. Deployï¼šå•Ÿå‹•æœå‹™

```bash
docker compose up
```

å•Ÿå‹•å…§å®¹ï¼š
- å•Ÿå‹• Ollama æœå‹™ (http://localhost:11434)
- å•Ÿå‹• Blender-RAG æŸ¥è©¢ api server (http://localhost:7860)

## ğŸ‘‰ ç¾åœ¨å¯ä»¥é€é HTTP API ç›´æ¥ POST æŸ¥è©¢ï¼

---

# æ³¨æ„äº‹é …

- é¦–æ¬¡ä½¿ç”¨å¿…é ˆå…ˆåŸ·è¡Œ `build`
- è‹¥ Blender æ‰‹å†Šæœ‰æ›´æ–°ï¼Œé‡æ–° `build`å³å¯
- å¦‚éœ€åˆ‡æ›æ¨¡å‹ï¼Œå¯åœ¨ Ollama å°æ‡‰æŒ‡ä»¤ï¼š
  ```bash
  docker exec -it ollama ollama run llama3
  ```

---

# ğŸ’¼ å®Œæ•´æ¨¹ç‹€åœ–

```bash
blender-rag-ai/
â”œâ”€â”€ app/
â”‚   â””â”€â”€ api.py            # æä¾›æŸ¥è©¢ API
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw_html/          # åŸå§‹ HTML è³‡æ–™
â”‚   â”œâ”€â”€ cleaned_texts/     # æ¸…ç†å¾Œçš„ç´”æ–‡å­—
â”‚   â””â”€â”€ faiss_index/       # FAISS å‘é‡è³‡æ–™åº«
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ crawl_blender_manual.py   # ä¸‹è¼‰ Blender æ‰‹å†Š
â”‚   â”œâ”€â”€ clean_html_extract.py     # HTML æ¸…ç†
â”‚   â”œâ”€â”€ build_embedding_index.py  # å»ºå‘é‡è³‡æ–™åº«
â”‚   â””â”€â”€ query_rag.py               # æŸ¥è©¢èˆ‡çµ„ Prompt
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```
